 ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/providers/http/sensors/http.py", line 164, in execute
    super().execute(context=context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/sensors/base.py", line 292, in execute
    time.sleep(self._get_next_poke_interval(started_at, run_duration, poke_count))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-12-16, 16:19:07 EET] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=dag_http_sensor_sanctions, task_id=check_new_sanctions, run_id=scheduled__2024-12-16T13:30:00+00:00, execution_date=20241216T133000, start_date=, end_date=20241216T141907
[2024-12-16, 16:19:07 EET] {standard_task_runner.py:110} ERROR - Failed to execute job 6767 for task check_new_sanctions ((psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(dag_http_sensor_sanctions, 2024-12-16 13:30:00+00) already exists.
[SQL: INSERT INTO dag_run (id, dag_id, queued_at, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, data_interval_start, data_interval_end, last_scheduling_decision, dag_hash, log_template_id, updated_at, clear_number) VALUES (%(id)s, %(dag_id)s, %(queued_at)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(data_interval_start)s, %(data_interval_end)s, %(last_scheduling_decision)s, %(dag_hash)s, %(log_template_id)s, %(updated_at)s, %(clear_number)s)]
[parameters: {'id': 1062, 'dag_id': 'dag_http_sensor_sanctions', 'queued_at': datetime.datetime(2024, 12, 16, 14, 8, 38, 152941, tzinfo=Timezone('UTC')), 'execution_date': datetime.datetime(2024, 12, 16, 13, 30, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2024, 12, 16, 14, 8, 38, 188058, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'scheduled__2024-12-16T13:30:00+00:00', 'creating_job_id': 6693, 'external_trigger': False, 'run_type': 'scheduled', 'conf': <psycopg2.extensions.Binary object at 0x7f850572fab0>, 'data_interval_start': datetime.datetime(2024, 12, 16, 13, 30, tzinfo=Timezone('UTC')), 'data_interval_end': datetime.datetime(2024, 12, 16, 14, 0, tzinfo=Timezone('UTC')), 'last_scheduling_decision': datetime.datetime(2024, 12, 16, 14, 8, 39, 636425, tzinfo=Timezone('UTC')), 'dag_hash': '178e01faf6bd987f18b372fb928a4934', 'log_template_id': 1, 'updated_at': datetime.datetime(2024, 12, 16, 14, 8, 39, 667532, tzinfo=Timezone('UTC')), 'clear_number': 0}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 98)
[2024-12-16, 16:19:07 EET] {process_utils.py:80} INFO - Process psutil.Process(pid=98, status='terminated', exitcode=1, started='14:08:41') (98) terminated with exit code 1
